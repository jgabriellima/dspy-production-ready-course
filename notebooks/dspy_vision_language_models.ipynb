{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Language Models com DSPy\n",
    "\n",
    "Trabalhar com imagens em DSPy é idêntico a trabalhar com texto: declare a Signature, o framework cuida do resto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Configuração inicial: modelo VLM e API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', 'your-api-key-here')\n",
    "vision_model = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=GEMINI_API_KEY)\n",
    "dspy.configure(lm=vision_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Imagens\n",
    "\n",
    "`dspy.Image` suporta: `from_url()`, `from_path()`, `from_bytes()`, `from_pil()`. A mesma Signature funciona para qualquer origem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://raw.githubusercontent.com/AdoHaha/dspy_fun/refs/heads/main/example_files/image_numbers.png\"\n",
    "numbers_image = dspy.Image.from_url(image_url)\n",
    "\n",
    "from IPython.display import Image, display\n",
    "display(Image(image_url, width=400))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signatures com Imagens\n",
    "\n",
    "Use `dspy.Image` como tipo de campo. Combina com campos textuais. Outputs estruturados funcionam automaticamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class ImageDescription(dspy.Signature):\n",
    "    \"\"\"Descreve o conteúdo de uma imagem de forma detalhada.\"\"\"\n",
    "    image: dspy.Image = dspy.InputField(desc=\"Imagem para análise\")\n",
    "    description: str = dspy.OutputField(desc=\"Descrição detalhada do conteúdo da imagem\")\n",
    "\n",
    "image_describer = dspy.Predict(ImageDescription)\n",
    "result = image_describer(image=numbers_image)\n",
    "result.description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção com Bounding Boxes\n",
    "\n",
    "Outputs estruturados (List[Dict]) retornam JSON automaticamente. Coordenadas normalizadas (0-1000).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberDetections(dspy.Signature):\n",
    "    \"\"\"Detecta todos os números (não dígitos isolados) na imagem e retorna bounding boxes.\n",
    "    \n",
    "    Coordenadas normalizadas (0-1000) em formato xyxy: x_min, y_min, x_max, y_max.\n",
    "    Retorna lista vazia se nenhum número for encontrado.\n",
    "    \"\"\"\n",
    "    image: dspy.Image = dspy.InputField(desc=\"Imagem para análise\")\n",
    "    boxes: List[Dict] = dspy.OutputField(\n",
    "        desc=\"Um dict por número com coordenadas normalizadas (0-1000): \"\n",
    "             \"{'x_min': int, 'y_min': int, 'x_max': int, 'y_max': int, 'number': float}\"\n",
    "    )\n",
    "\n",
    "number_detector = dspy.Predict(NumberDetections)\n",
    "detections = number_detector(image=numbers_image)\n",
    "detections.boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização\n",
    "\n",
    "Função auxiliar para desenhar bounding boxes sobre a imagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "\n",
    "def draw_detections(image_url: str, detections: List[Dict]) -> Image.Image:\n",
    "    \"\"\"Desenha bounding boxes e labels sobre a imagem.\"\"\"\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        img_data = response.read()\n",
    "    img = Image.open(BytesIO(img_data))\n",
    "    \n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for detection in detections:\n",
    "        x_min = int(detection[\"x_min\"] * img.width / 1000)\n",
    "        y_min = int(detection[\"y_min\"] * img.height / 1000)\n",
    "        x_max = int(detection[\"x_max\"] * img.width / 1000)\n",
    "        y_max = int(detection[\"y_max\"] * img.height / 1000)\n",
    "        \n",
    "        draw.rectangle([(x_min, y_min), (x_max, y_max)], outline=\"red\", width=3)\n",
    "        draw.text((x_min, y_min - 20), str(detection[\"number\"]), fill=\"red\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "annotated_image = draw_detections(image_url, detections.boxes)\n",
    "display(annotated_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Texto + Imagem\n",
    "\n",
    "Signatures podem combinar campos de imagem e texto. VQA (Visual Question Answering) é trivial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualQuestionAnswering(dspy.Signature):\n",
    "    \"\"\"Responde perguntas sobre o conteúdo de uma imagem.\"\"\"\n",
    "    image: dspy.Image = dspy.InputField(desc=\"Imagem para análise\")\n",
    "    question: str = dspy.InputField(desc=\"Pergunta sobre a imagem\")\n",
    "    answer: str = dspy.OutputField(desc=\"Resposta detalhada baseada na imagem\")\n",
    "\n",
    "vqa = dspy.Predict(VisualQuestionAnswering)\n",
    "result = vqa(\n",
    "    image=numbers_image,\n",
    "    question=\"Quantos números diferentes aparecem na imagem? Qual é a soma deles?\"\n",
    ")\n",
    "result.answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulos Avançados\n",
    "\n",
    "`ChainOfThought`, `ReAct` e outros módulos funcionam com imagens sem modificação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageAnalysis(dspy.Signature):\n",
    "    \"\"\"Análise detalhada de imagem com raciocínio passo a passo.\"\"\"\n",
    "    image: dspy.Image = dspy.InputField(desc=\"Imagem para análise\")\n",
    "    analysis: str = dspy.OutputField(desc=\"Análise detalhada com raciocínio\")\n",
    "    key_findings: str = dspy.OutputField(desc=\"Principais descobertas\")\n",
    "\n",
    "image_analyzer = dspy.ChainOfThought(ImageAnalysis)\n",
    "result = image_analyzer(image=numbers_image)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulos Customizados\n",
    "\n",
    "Combine múltiplas operações visuais seguindo o mesmo padrão de módulos textuais.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComprehensiveImageAnalysis(dspy.Module):\n",
    "    \"\"\"Módulo que combina detecção e análise de imagem.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.detector = dspy.Predict(NumberDetections)\n",
    "        self.analyzer = dspy.ChainOfThought(ImageAnalysis)\n",
    "    \n",
    "    def forward(self, image: dspy.Image):\n",
    "        detections = self.detector(image=image)\n",
    "        analysis = self.analyzer(image=image)\n",
    "        \n",
    "        return dspy.Prediction(\n",
    "            detections=detections.boxes,\n",
    "            analysis=analysis.analysis,\n",
    "            findings=analysis.key_findings\n",
    "        )\n",
    "\n",
    "comprehensive_analyzer = ComprehensiveImageAnalysis()\n",
    "result = comprehensive_analyzer(image=numbers_image)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custo e Performance\n",
    "\n",
    "VLMs são mais caros que LLMs. DSPy fornece histórico de custos por chamada via `lm.history[-1][\"cost\"]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vision_model.history:\n",
    "    last_call = vision_model.history[-1]\n",
    "    cost = last_call.get(\"cost\", 0)\n",
    "    tokens = last_call.get(\"tokens\", {})\n",
    "    \n",
    "    print(f\"Custo: ${cost:.6f}\")\n",
    "    print(f\"Tokens: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context Switching\n",
    "\n",
    "Use `dspy.context()` para alternar modelos VLM por tarefa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialized_vlm = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=GEMINI_API_KEY)\n",
    "\n",
    "with dspy.context(lm=specialized_vlm):\n",
    "    result = image_describer(image=numbers_image)\n",
    "    result.description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "**Insights:**\n",
    "- `dspy.Image` abstrai manipulação de imagens\n",
    "- Mesma interface para URLs, arquivos, bytes, PIL\n",
    "- Outputs estruturados funcionam automaticamente\n",
    "- Módulos avançados funcionam sem modificação\n",
    "- Context switching para modelos diferentes\n",
    "\n",
    "**Uso ideal:** OCR, análise de documentos, detecção de objetos, VQA, análise de gráficos.\n",
    "\n",
    "**Limitações:** Custo maior, latência maior, requer modelos VLM especializados.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}