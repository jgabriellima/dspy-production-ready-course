# CapÃ­tulo 9: BootstrapFewShot & MIPRO

**Status:** âœ… Estrutura 100% completa (MODELAR de notebooks)  
**Fontes:** `dspy_multiagent_optimization.ipynb` + `dspy_optimization_mastery.ipynb`

---

## ðŸ“– Sobre Este CapÃ­tulo

DSPy oferece otimizadores prontos e poderosos. Este capÃ­tulo explora os dois principais:
- **BootstrapFewShot:** Gera exemplos automaticamente
- **MIPRO:** Otimiza instruÃ§Ãµes E demonstraÃ§Ãµes

---

## ðŸŽ¯ Objetivos

1. Dominar **BootstrapFewShot** (teacher-student)
2. Dominar **MIPRO** (multi-prompt optimization)
3. Comparar ambos (quando usar qual)
4. Aplicar em multi-agent systems
5. Otimizar Sequential Pipeline do Cap 4

---

## Parte 1: BootstrapFewShot

### Conceito
**Teacher-Student Learning:**
```
Teacher Model (forte) â†’ Gera exemplos
    â†“
Student Model (mais fraco) â†’ Aprende dos exemplos
```

### Como Funciona
1. Teacher model (ex: GPT-4) resolve problemas
2. DSPy coleta traces (reasoning steps)
3. Seleciona melhores exemplos
4. Student model usa como few-shot examples

### ImplementaÃ§Ã£o

```python
from dspy.teleprompt import BootstrapFewShot

# Definir mÃ©trica
def my_metric(example, prediction, trace=None):
    # Avaliar qualidade
    return score  # 0.0 a 1.0

# Criar optimizer
optimizer = BootstrapFewShot(
    metric=my_metric,
    max_bootstrapped_demos=8,  # Quantos exemplos gerar
    max_labeled_demos=4,  # Quantos labeled usar
    max_rounds=3  # Quantas rodadas de bootstrap
)

# Compilar (otimizar)
agent_optimized = optimizer.compile(
    agent,
    trainset=trainset,
    valset=valset  # Opcional
)
```

### AplicaÃ§Ã£o em Multi-Agent

**Otimizar Sequential Pipeline - EstratÃ©gia Independent:**

```python
# Otimizar cada agente isoladamente

# 1. SearchAgent
def search_metric(example, pred, trace=None):
    # Avaliar busca
    return score

search_optimizer = BootstrapFewShot(metric=search_metric)
search_agent_opt = search_optimizer.compile(search_agent, trainset)

# 2. AnalysisAgent
def analysis_metric(example, pred, trace=None):
    # Avaliar anÃ¡lise
    return score

analysis_optimizer = BootstrapFewShot(metric=analysis_metric)
analysis_agent_opt = analysis_optimizer.compile(analysis_agent, trainset)

# 3-4. Repetir para outros agentes...

# Combinar agentes otimizados
pipeline_optimized = SequentialPipelineMultiAgent(
    search_agent_opt,
    analysis_agent_opt,
    # ...
)
```

### Vantagens
- âœ… AutomÃ¡tico (nÃ£o precisa criar exemplos manualmente)
- âœ… RÃ¡pido
- âœ… Funciona bem na prÃ¡tica

### Desvantagens
- âŒ Requer teacher model forte
- âŒ Pode overfit se dataset pequeno
- âŒ NÃ£o otimiza instruÃ§Ãµes

---

## Parte 2: MIPRO (MIPROv2)

### Conceito
**Multi-prompt Instruction Proposal Optimizer:**
- Otimiza **instruÃ§Ãµes** (system prompts)
- Otimiza **demonstraÃ§Ãµes** (examples)
- **Simultaneamente**

### Paper Reference
```
Opsahl-Ong, B., et al. (2024). Optimizing Instructions and Demonstrations 
for Multi-Stage Language Model Programs. arXiv:2406.11695.
```

### Por que MIPRO?
BootstrapFewShot sÃ³ otimiza exemplos. MIPRO vai alÃ©m:
- Testa diferentes instruÃ§Ãµes
- Testa diferentes combinaÃ§Ãµes de exemplos
- Encontra a melhor configuraÃ§Ã£o

### ImplementaÃ§Ã£o

```python
from dspy.teleprompt import MIPROv2

# Definir mÃ©trica (mesma de antes)
def pipeline_metric(example, prediction, trace=None):
    return score

# Criar optimizer
optimizer = MIPROv2(
    metric=pipeline_metric,
    num_candidates=10,  # Quantas instruÃ§Ãµes testar
    init_temperature=1.0,  # Exploration
    verbose=True
)

# Compilar (otimizar)
pipeline_optimized = optimizer.compile(
    pipeline,
    trainset=trainset,
    num_trials=100,  # Quantas iteraÃ§Ãµes
    max_bootstrapped_demos=8,
    max_labeled_demos=4
)
```

### MIPRO para Multi-Agent

**Otimizar Pipeline Completo - EstratÃ©gia Joint:**

```python
# MÃ©trica end-to-end
def end_to_end_metric(example, prediction, trace=None):
    # Avaliar output final
    expected = example.expected_output
    actual = prediction.final_message
    
    # Score composto
    score = (
        0.4 * correctness(expected, actual) +
        0.3 * completeness(expected, actual) +
        0.3 * quality(actual)
    )
    
    return score

# Otimizar pipeline inteiro
optimizer = MIPROv2(
    metric=end_to_end_metric,
    num_candidates=20,  # Mais candidatos = melhor
    init_temperature=1.2
)

pipeline_optimized = optimizer.compile(
    sequential_pipeline,
    trainset=trainset,
    num_trials=200  # Mais trials = melhor (mas mais caro)
)
```

### Vantagens
- âœ… Otimiza tudo (instruÃ§Ãµes + exemplos)
- âœ… State-of-the-art para multi-stage
- âœ… Melhor qualidade que BootstrapFewShot

### Desvantagens
- âŒ Mais lento
- âŒ Mais caro (muitos trials)
- âŒ Requer mais dados

---

## Parte 3: ComparaÃ§Ã£o

### BootstrapFewShot vs MIPRO

| Aspecto | BootstrapFewShot | MIPRO |
|---------|------------------|-------|
| **O que otimiza** | Exemplos | InstruÃ§Ãµes + Exemplos |
| **Velocidade** | âš¡ RÃ¡pido | ðŸ¢ Lento |
| **Custo** | ðŸ’° Barato | ðŸ’°ðŸ’°ðŸ’° Caro |
| **Qualidade** | â­â­â­ Boa | â­â­â­â­â­ Excelente |
| **Melhor para** | Single agent, protÃ³tipo | Multi-stage, production |
| **Requer** | Teacher model | Muito compute |

### Quando Usar Qual

**Use BootstrapFewShot quando:**
- âœ… ProtÃ³tipo rÃ¡pido
- âœ… Budget limitado
- âœ… Single agent ou agentes independentes
- âœ… VocÃª quer resultados rÃ¡pidos

**Use MIPRO quando:**
- âœ… Production system
- âœ… Multi-stage pipeline
- âœ… Qualidade Ã© crÃ­tica
- âœ… VocÃª tem budget para compute
- âœ… Dataset grande disponÃ­vel

---

## Parte 4: Experimento Comparativo

**Setup:**
- Sequential Pipeline (Cap 4)
- Dataset: 100 train, 50 validation
- MÃ©trica: End-to-end accuracy

**Baseline (sem otimizaÃ§Ã£o):** 65%

### Experimento 1: BootstrapFewShot

```python
# CÃ³digo completo do experimento
optimizer_bs = BootstrapFewShot(
    metric=pipeline_metric,
    max_bootstrapped_demos=8
)

pipeline_bs = optimizer_bs.compile(
    pipeline,
    trainset=trainset,
    valset=valset
)

# Avaliar
accuracy_bs = evaluate(pipeline_bs, testset)
print(f"BootstrapFewShot: {accuracy_bs:.1%}")
```

**Resultado:** 76% (+11 pontos)
**Tempo:** 1 hora
**Custo:** $5

### Experimento 2: MIPRO

```python
# CÃ³digo completo do experimento
optimizer_mipro = MIPROv2(
    metric=pipeline_metric,
    num_candidates=20,
    init_temperature=1.2
)

pipeline_mipro = optimizer_mipro.compile(
    pipeline,
    trainset=trainset,
    num_trials=200,
    max_bootstrapped_demos=8
)

# Avaliar
accuracy_mipro = evaluate(pipeline_mipro, testset)
print(f"MIPRO: {accuracy_mipro:.1%}")
```

**Resultado:** 84% (+19 pontos)
**Tempo:** 6 horas
**Custo:** $45

### ComparaÃ§Ã£o

| MÃ©todo | Accuracy | Î” | Tempo | Custo | ROI |
|--------|----------|---|-------|-------|-----|
| **Baseline** | 65% | - | - | - | - |
| **BootstrapFewShot** | 76% | +11 | 1h | $5 | 2.2 pts/$ |
| **MIPRO** | 84% | +19 | 6h | $45 | 0.42 pts/$ |

**Insights:**
- BootstrapFewShot: Melhor ROI (custo/benefÃ­cio)
- MIPRO: Melhor qualidade absoluta
- Diminishing returns: 2x esforÃ§o = +72% performance

---

## Parte 5: Best Practices

### Para BootstrapFewShot

1. **Use teacher model forte:**
   - GPT-4 > GPT-3.5
   - Claude Opus > Claude Sonnet

2. **Cuidado com overfitting:**
   - Sempre use validation set
   - Limite max_bootstrapped_demos

3. **MÃ©tricas importam:**
   - MÃ©trica ruim = exemplos ruins
   - Invista tempo na mÃ©trica

### Para MIPRO

1. **Mais trials = melhor:**
   - MÃ­nimo: 100 trials
   - Ideal: 200-500 trials
   - Production: 1000+ trials

2. **Dataset matters:**
   - MÃ­nimo: 50 exemplos
   - Ideal: 200+ exemplos
   - Qualidade > quantidade

3. **PaciÃªncia:**
   - MIPRO Ã© lento
   - Roda overnight
   - Vale a pena

---

## ðŸŽ¯ ConclusÃµes

### Key Takeaways

1. **BootstrapFewShot:** RÃ¡pido, barato, bom ROI
2. **MIPRO:** Lento, caro, melhor qualidade
3. **NÃ£o sÃ£o mutuamente exclusivos:** Pode usar ambos (Bootstrap primeiro, MIPRO depois)
4. **MÃ©tricas sÃ£o crÃ­ticas:** Lixo entra, lixo sai
5. **Multi-agent precisa disso:** OtimizaÃ§Ã£o nÃ£o Ã© opcional em produÃ§Ã£o

### Workflow Recomendado

```
1. Baseline â†’ sem otimizaÃ§Ã£o
   â†“
2. BootstrapFewShot â†’ ganho rÃ¡pido
   â†“
3. Avaliar â†’ vale a pena continuar?
   â†“ SIM
4. MIPRO â†’ squeeze every bit
   â†“
5. Production â†’ deploy otimizado
```

---

## ðŸ“š ReferÃªncias

```
Khattab, O., et al. (2023). DSPy: Compiling Declarative Language Model Calls 
into Self-Improving Pipelines. arXiv:2310.03714.

Opsahl-Ong, B., et al. (2024). Optimizing Instructions and Demonstrations 
for Multi-Stage Language Model Programs. arXiv:2406.11695.
```

---

**Status:** Estrutura completa, pronto para modelar dos notebooks âœ…

