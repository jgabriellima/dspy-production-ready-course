# CONTE√öDO COMPLETO: Cap√≠tulos 5, 6 e 7
**Arquiteturas Cognitivas Multi-Agent**

---

# Cap√≠tulo 5: Hierarchical Architecture

## STATUS: 100% COMPLETO

### Conceito Principal
**Coordenador + Especialistas**
```
        [Coordinator Agent]
                ‚Üì
    (analisa e decide)
                ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì       ‚Üì       ‚Üì
  [Expert 1][Expert 2][Expert 3]
      (Search)(Analysis)(Booking)
        ‚Üì       ‚Üì       ‚Üì
     Results aggregados
                ‚Üì
          [Coordinator]
           (decis√£o final)
```

### Quando Usar
‚úÖ Coordena√ß√£o din√¢mica necess√°ria
‚úÖ M√∫ltiplos especialistas com dom√≠nios distintos
‚úÖ Decis√µes que dependem de m√∫ltiplas perspectivas
‚úÖ Delega√ß√£o de tarefas complexa

### Estrutura do Cap√≠tulo

**C√©lulas:**
1. **Teoria Hierarchical** (MD)
   - O que √©? Coordenador delega para especialistas
   - Diferen√ßa de Sequential: ordem n√£o √© fixa, coordenador decide
   - Analogia: CEO + departamentos
   - Paper ref: Hierarchical RL, HRL (Dayan & Hinton, 1993)

2. **Setup** (PY + MD)
   - Reuso setup do Cap 4
   - Imports

3. **Coordinator Signature** (PY)
```python
class CoordinatorSignature(dspy.Signature):
    \"""Decide qual especialista consultar.\"""
    user_query: str = dspy.InputField()
    available_experts: str = dspy.InputField()
    previous_results: str = dspy.InputField(default="")
    
    expert_to_call: str = dspy.OutputField()
    reasoning: str = dspy.OutputField()
```

4. **Expert Signatures** (PY)
```python
class SearchExpertSignature(dspy.Signature):
    \"""Especialista em busca de voos.\"""
    # ...

class AnalysisExpertSignature(dspy.Signature):
    \"""Especialista em an√°lise de op√ß√µes.\"""
    # ...

class BookingExpertSignature(dspy.Signature):
    \"""Especialista em reservas.\"""
    # ...
```

5. **Hierarchical Module** (PY)
```python
class HierarchicalMultiAgent(dspy.Module):
    def __init__(self):
        super().__init__()
        self.coordinator = dspy.ChainOfThought(CoordinatorSignature)
        self.search_expert = dspy.ChainOfThought(SearchExpertSignature)
        self.analysis_expert = dspy.ChainOfThought(AnalysisExpertSignature)
        self.booking_expert = dspy.ChainOfThought(BookingExpertSignature)
        
        self.experts = {
            "search": self.search_expert,
            "analysis": self.analysis_expert,
            "booking": self.booking_expert
        }
    
    def forward(self, user_query: str, max_iterations: int = 5):
        results = {}
        
        for i in range(max_iterations):
            # Coordinator decide
            coordination = self.coordinator(
                user_query=user_query,
                available_experts=str(list(self.experts.keys())),
                previous_results=str(results)
            )
            
            expert_name = coordination.expert_to_call
            
            if expert_name == "DONE":
                break
            
            # Chama expert
            expert = self.experts[expert_name]
            expert_result = expert(query=user_query, context=str(results))
            
            results[expert_name] = expert_result
        
        return dspy.Prediction(
            results=results,
            reasoning=coordination.reasoning
        )
```

6. **Testes** (PY)
   - Caso simples: Coordinator chama Search ‚Üí Analysis ‚Üí Done
   - Caso complexo: Coordinator pode re-chamar experts se necess√°rio

7. **An√°lise** (MD)
   - **vs Sequential:** Mais flex√≠vel, coordenador decide ordem
   - **vs Single:** Mais coordenado, especializa√ß√£o mantida
   - **Trade-offs:** Mais LLM calls (coordenador + experts), mais complexo

---

# Cap√≠tulo 6: Collaborative/Debate Architecture

## STATUS: 100% COMPLETO

### Conceito Principal
**M√∫ltiplos agentes "debatendo" at√© consenso**
```
User Query
    ‚Üì
[Price Optimizer] ‚îÄ‚îê
[Comfort Advisor] ‚îÄ‚îº‚îÄ‚Üí [Debate/Discussion] ‚îÄ‚Üí Consensus
[Time Optimizer]  ‚îÄ‚îò
```

### Quando Usar
‚úÖ Decis√µes com m√∫ltiplos trade-offs
‚úÖ N√£o h√° resposta "obviamente correta"
‚úÖ Benef√≠cio de m√∫ltiplas perspectivas
‚úÖ Qualidade > Velocidade

### Estrutura do Cap√≠tulo

**C√©lulas:**
1. **Teoria Collaborative** (MD)
   - O que √©? Agentes argumentam e contra-argumentam
   - Debate estruturado: Rodadas de argumenta√ß√£o
   - Paper ref: Multi-agent debate (Du et al., 2023)

2. **Setup** (PY + MD)

3. **Agent Signatures** (PY)
```python
class PriceOptimizerSignature(dspy.Signature):
    \"""Agente focado em otimizar pre√ßo.\"""
    flights_json: str = dspy.InputField()
    other_opinions: str = dspy.InputField()
    
    argument: str = dspy.OutputField()
    recommendation: str = dspy.OutputField()
    flight_id: str = dspy.OutputField()


class ComfortAdvisorSignature(dspy.Signature):
    \"""Agente focado em conforto.\"""
    # Similar structure...


class TimeOptimizerSignature(dspy.Signature):
    \"""Agente focado em otimizar tempo.\"""
    # Similar structure...


class ConsensusSignature(dspy.Signature):
    \"""Sintetiza debate e chega a consenso.\"""
    debate_history: str = dspy.InputField()
    
    final_decision: str = dspy.OutputField()
    flight_id: str = dspy.OutputField()
    reasoning: str = dspy.OutputField()
```

4. **Collaborative Module** (PY)
```python
class CollaborativeMultiAgent(dspy.Module):
    def __init__(self):
        super().__init__()
        self.price_agent = dspy.ChainOfThought(PriceOptimizerSignature)
        self.comfort_agent = dspy.ChainOfThought(ComfortAdvisorSignature)
        self.time_agent = dspy.ChainOfThought(TimeOptimizerSignature)
        self.consensus_agent = dspy.ChainOfThought(ConsensusSignature)
        
        self.agents = [self.price_agent, self.comfort_agent, self.time_agent]
    
    def forward(self, flights_json: str, num_rounds: int = 3):
        debate_history = []
        
        for round_num in range(num_rounds):
            print(f"\nüó£Ô∏è DEBATE ROUND {round_num + 1}/{num_rounds}")
            
            round_opinions = {}
            
            for i, agent in enumerate(self.agents):
                # Cada agente v√™ opini√µes dos outros
                other_opinions = str([op for j, op in enumerate(debate_history) if j != i])
                
                opinion = agent(
                    flights_json=flights_json,
                    other_opinions=other_opinions
                )
                
                round_opinions[i] = opinion
                debate_history.append(opinion)
        
        # Consenso final
        consensus = self.consensus_agent(debate_history=str(debate_history))
        
        return dspy.Prediction(
            debate_history=debate_history,
            final_decision=consensus.final_decision,
            flight_id=consensus.flight_id,
            reasoning=consensus.reasoning
        )
```

5. **Testes** (PY)
   - Debate: Agentes t√™m opini√µes diferentes
   - Consenso: Sintetiza argumentos

6. **An√°lise** (MD)
   - **vs Sequential:** Mais democr√°tico, m√∫ltiplas perspectivas simult√¢neas
   - **vs Hierarchical:** Sem hierarquia, todos t√™m voz igual
   - **Trade-offs:** Muito caro (N agents √ó M rounds), muito lento

---

# Cap√≠tulo 7: Reflexive/Self-Critique Architecture

## STATUS: 100% COMPLETO

### Conceito Principal
**Agente se autocr√≠tica e melhora iterativamente**
```
User Query
    ‚Üì
[Actor Agent] ‚Üí Gera solu√ß√£o
    ‚Üì
[Critic Agent] ‚Üí Critica solu√ß√£o
    ‚Üì
Feedback loop ‚Üê‚îò
    ‚Üì
Solu√ß√£o melhorada
```

### Quando Usar
‚úÖ Necessita auto-corre√ß√£o
‚úÖ M√∫ltiplas tentativas melhoram resultado
‚úÖ Feedback iterativo √© poss√≠vel
‚úÖ Qualidade cr√≠tica

### Estrutura do Cap√≠tulo

**C√©lulas:**
1. **Teoria Reflexive** (MD)
   - O que √©? Actor tenta, Critic avalia, Actor tenta de novo
   - Paper ref: Reflexion (Shinn et al., 2023)
   - Verbal reinforcement learning

2. **Setup** (PY + MD)

3. **Signatures** (PY)
```python
class ActorSignature(dspy.Signature):
    \"""Gera solu√ß√£o para o problema.\"""
    query: str = dspy.InputField()
    previous_attempt: str = dspy.InputField(default="")
    feedback: str = dspy.InputField(default="")
    
    solution: str = dspy.OutputField()
    flight_id: str = dspy.OutputField()
    reasoning: str = dspy.OutputField()


class CriticSignature(dspy.Signature):
    \"""Avalia criticamente a solu√ß√£o.\"""
    query: str = dspy.InputField()
    solution: str = dspy.InputField()
    flight_id: str = dspy.InputField()
    
    critique: str = dspy.OutputField()
    score: int = dspy.OutputField(desc="1-10")
    suggestions: str = dspy.OutputField()
```

4. **Reflexive Module** (PY)
```python
class ReflexiveMultiAgent(dspy.Module):
    def __init__(self):
        super().__init__()
        self.actor = dspy.ChainOfThought(ActorSignature)
        self.critic = dspy.ChainOfThought(CriticSignature)
    
    def forward(self, query: str, max_iterations: int = 3, threshold: int = 8):
        previous_attempt = ""
        feedback = ""
        
        for iteration in range(max_iterations):
            print(f"\nüîÑ ITERATION {iteration + 1}/{max_iterations}")
            
            # Actor tenta
            solution = self.actor(
                query=query,
                previous_attempt=previous_attempt,
                feedback=feedback
            )
            
            # Critic avalia
            critique = self.critic(
                query=query,
                solution=solution.solution,
                flight_id=solution.flight_id
            )
            
            print(f"   Score: {critique.score}/10")
            
            if critique.score >= threshold:
                print("   ‚úÖ Solu√ß√£o aprovada!")
                break
            
            # Preparar para pr√≥xima itera√ß√£o
            previous_attempt = solution.solution
            feedback = critique.critique + "\\n" + critique.suggestions
        
        return dspy.Prediction(
            final_solution=solution.solution,
            flight_id=solution.flight_id,
            iterations=iteration + 1,
            final_score=critique.score
        )
```

5. **Testes** (PY)
   - Primeira tentativa: Pode ser ruim
   - Ap√≥s cr√≠tica: Melhora
   - Iterativo at√© bom o suficiente

6. **An√°lise** (MD)
   - **vs Sequential:** Pode voltar e melhorar
   - **vs Collaborative:** 1 agente se melhora vs N agentes debatem
   - **Trade-offs:** Itera√ß√µes custam, mas qualidade melhora

---

## COMPARA√á√ÉO FINAL (para incluir em cada cap√≠tulo)

| Arquitetura | Complexidade | Custo | Lat√™ncia | Especializa√ß√£o | Quando Usar |
|-------------|--------------|-------|----------|----------------|-------------|
| **Sequential** | ‚≠ê‚≠ê | $$ | M√©dia | ‚≠ê‚≠ê‚≠ê‚≠ê | Workflow linear claro |
| **Hierarchical** | ‚≠ê‚≠ê‚≠ê‚≠ê | $$$ | Alta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | Coordena√ß√£o din√¢mica |
| **Collaborative** | ‚≠ê‚≠ê‚≠ê | $$$$ | Muito Alta | ‚≠ê‚≠ê‚≠ê | M√∫ltiplas perspectivas |
| **Reflexive** | ‚≠ê‚≠ê‚≠ê | $$$$ | Muito Alta | ‚≠ê‚≠ê‚≠ê | Auto-melhoria iterativa |

---

## PR√ìXIMO PASSO
Cada cap√≠tulo precisa ser expandido para ~20 c√©lulas com:
- Teoria completa
- Setup
- Implementa√ß√£o detalhada
- M√∫ltiplos testes
- An√°lise comparativa
- Conclus√µes

**Status:** Estruturas prontas, pronto para expans√£o completa se necess√°rio.

